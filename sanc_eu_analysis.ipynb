{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434e89c-36d7-4a45-82e5-b6e177c30082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import functions # specific module for additional functions for this code\n",
    "from glob import glob\n",
    "pd.set_option('display.width', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387048a-4983-4175-9703-36efd4f3701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these urls target two different but complementary files \n",
    "# the response is actually really easy to read, so it's possible to directly DataFrame it\n",
    "url1 = 'https://webgate.ec.europa.eu/fsd/fsf/public/files/csvFullSanctionsList/content?token=dG9rZW4tMjAxNw'\n",
    "df_1 = pd.read_csv(url1, sep=';')\n",
    "url2 = 'https://webgate.ec.europa.eu/fsd/fsf/public/files/csvFullSanctionsList_1_1/content?token=dG9rZW4tMjAxNw'\n",
    "df_2 = pd.read_csv(url2, sep=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41238fe2-d44f-47c9-a7db-a1dad544d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets isolate the columns needed for the purpose of this codes \n",
    "# 'replace_blanks' is a function called from the module defined below. For details about the function, please open the module and read the comments\n",
    "df_1 = df_1[['Entity_logical_id', 'Leba_publication_date', 'Programme', 'Naal_wholename', 'Subject_type', 'Leba_numtitle', 'Addr_country']]\n",
    "df_2['listing_date'] = df_2.apply(functions.replace_blanks, axis=1)\n",
    "df_2 = df_2[['Entity_LogicalId', 'listing_date', 'Entity_SubjectType', 'Entity_Regulation_Programme', 'NameAlias_WholeName', 'Entity_Regulation_NumberTitle', 'Address_CountryIso2Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7a9b9-baba-4e1d-ac2b-9fe5547dc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize columns name: \n",
    "# everytihng that's referred to the single sanctioned subject has 'sanctioned_' before the col name\n",
    "# everytihng that's referred to the sanction itself has 'sanction_' before the col name\n",
    "new_names1 = {\n",
    "    'Entity_logical_id': 'sanctioned_id',\n",
    "    'Leba_publication_date': 'sanction_listing_date',\n",
    "    'Subject_type': 'sanctioned_type',\n",
    "    'Programme': 'sanction_programme',\n",
    "    'Leba_numtitle': 'sanction_regulation',\n",
    "    'Naal_wholename': 'sanctioned_aliases',\n",
    "    'Addr_country': 'sanctioned_country_iso3'\n",
    "}\n",
    "\n",
    "df_1 = df_1.rename(columns=new_names1)\n",
    "\n",
    "new_names2 = {\n",
    "    'Entity_LogicalId': 'entity_id',\n",
    "    'Entity_DesignationDate': 'sanction_listing_date',\n",
    "    'Entity_SubjectType': 'sanctioned_type',\n",
    "    'Entity_Regulation_Programme': 'sanction_programme',\n",
    "    'Entity_Regulation_NumberTitle': 'sanction_regulation',\n",
    "    'NameAlias_WholeName': 'sanctioned_aliases',\n",
    "    'Address_CountryIso2Code': 'sanctioned_country_iso2'\n",
    "}\n",
    "\n",
    "df_2 = df_2.rename(columns=new_names2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d3eb3-ce29-4778-b8fe-bc477b03cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's build up the final DataFrame for the analysis\n",
    "df_eu = pd.concat([df_1, df_2], ignore_index=True)\n",
    "df_eu = df_eu.drop_duplicates()\n",
    "\n",
    "# get rid of useless DataFrames\n",
    "del df_1\n",
    "del df_2\n",
    "\n",
    "# a little bit of data manipulation. I'm creating a unique string for each sancion because the EU splits it in two columns\n",
    "df_eu['sanctioned_aliases'] = df_eu['sanctioned_aliases'].fillna('no eu alias')\n",
    "df_eu['sanction_text'] = df_eu['sanction_programme']+' - '+df_eu['sanction_regulation']\n",
    "\n",
    "# now select the columns needed and tracks the sanctioning body \n",
    "df_eu_analysis = df_eu[['sanctioned_id', 'sanctioned_country_iso2', 'sanctioned_country_iso3', 'sanction_text', 'sanctioned_type', 'sanction_listing_date']]\n",
    "df_eu_analysis['sanction_body'] = 'EU'\n",
    "del df_eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd3009e-416b-4162-9814-4355e0275e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell saves the DataFrame on your google drive (I use Google colab). You can just save he DataFrame on your local directory as well\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "df_eu_analysis.to_csv('/content/drive/My Drive/df_eu_analysis.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6daa90b-2240-4b26-87b2-2fb79945da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eu_analysis.to_csv('C:/Users/valer/OneDrive/Desktop/python/input/df_eu_analysis.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
